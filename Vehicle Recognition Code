import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import fcluster
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score

headers
headers = [
    'COMPACTNESS', 'CIRCULARITY', 'DISTANCE_CIRCULARITY', 'RADIUS_RATIO',
    'PR.AXIS_ASPECT_RATIO', 'MAX.LENGTH_ASPECT_RATIO', 'SCATTER_RATIO',
    'ELONGATEDNESS', 'PR.AXIS_RECTANGULARITY', 'MAX.LENGTH_RECTANGULARITY',
    'SCALED_VARIANCE_MAJOR', 'SCALED_VARIANCE_MINOR', 'SCALED_RADIUS_OF_GYRATION',
    'SKEWNESS_ABOUT_MAJOR', 'SKEWNESS_ABOUT_MINOR', 'KURTOSIS_ABOUT_MAJOR',
    'KURTOSIS_ABOUT_MINOR', 'HOLLOWS_RATIO', 'Class'
]
print("headers\n")

DATA-PREPROCESSING
df = pd.read_csv("data.csv.txt",names=headers,header=None)
df

df.head(5)

df.info()

df.isnull()

missing_data = df.isnull()
missing_data

missing_data = df.isnull()
for column in headers :
  print(column)
  print(missing_data[column].value_counts())
  print("")
  # Display missing data count for each column

 from sklearn.impute import SimpleImputer
 imputer_most_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
 df.iloc[:,:] = imputer_most_freq.fit_transform(df.iloc[:,:])
# Impute missing values with the most frequent value in each column

df.info()
# Display data info after imputation

X = df.drop(columns=['Class'])
y = df['Class']

LINEAR REGRESSION
y = pd.factorize(y)[0]

def linear_regression_single_feature(feature):
    X_feature = X[[feature]]
    X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.2, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    return mse, r2

# Generate predictions using the fitted model
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error (MSE): {mse}")
print(f"R² Score: {r2}")

results = {}
for feature in X.columns:
    mse, r2 = linear_regression_single_feature(feature)
    results[feature] = {'Mean Squared Error': mse, 'R² Score': r2}

for feature, metrics in results.items():
    print(f"Feature: {feature}")
    print(f"  Mean Squared Error: {metrics['Mean Squared Error']}")
    print(f"  R² Score: {metrics['R² Score']}")
    print("")
